{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gurd24wBp9jt"
      },
      "source": [
        "# Project 2: Non-Generative Model\n",
        "Authors: Zechen Wu, Elena Franchini, Erifeoluwa Jamgbadi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irVwI6K7mKcu"
      },
      "source": [
        "# Investigate dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qi67ytW1lZR"
      },
      "source": [
        "## Dataset selection\n",
        "The dataset we will use is the \"SQuAD2.0: The Stanford Question Answering Dataset\". The website provides the training and validation (i.e. development) set in the form of JSON.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aubwFnNu1wvt"
      },
      "source": [
        "## Dataset analysis\n",
        "Data in the training set consists of strings which represent questions and answers (that come from Wikipedia articles) and can be found as values under the 'data' key. Each 'title' key is associated to a 'paragraphs' key which is an array containing these questions and answers associated to that title (the title acts as a category). Each question is composed by the text representing the question, the id, an array of answers and a flag checking if answering to that question is impossible: if the flag is true, the array of answers is empty. In addition, each answer is associated to the 'answer_start' key whose value represent the starting position of the answer.\n",
        "Some questions have also plausible answers, which should be other possible answers in addition to the correct ones (if any)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4X4cGCDrnz1",
        "outputId": "75c049ca-dd7e-43e7-b527-da59b23a501e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AML_project2' already exists and is not an empty directory.\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Ele975/AML_project2.git\n",
        "!pip install --upgrade gensim\n",
        "!pip install -U sentence-transformers\n",
        "!pip install torchinfo\n",
        "!pip install datasets\n",
        "!pip install -U accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c3ZuKwj5B-Sg"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHKokF5XvTof",
        "outputId": "82df3a27-2e0e-439a-fe96-a32f4f040183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import math\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "##model parts imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statistics import mean, stdev\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import linear_model\n",
        "\n",
        "\n",
        "##for calculating the accuracy of the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn import metrics\n",
        "\n",
        "import os\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Tr2G1PvLM_",
        "outputId": "a6ba5274-9c36-416b-937b-e2c31d55741d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version                                               data\n",
            "0      v2.0  {'title': 'Beyoncé', 'paragraphs': [{'qas': [{...\n",
            "1      v2.0  {'title': 'Frédéric_Chopin', 'paragraphs': [{'...\n",
            "2      v2.0  {'title': 'Sino-Tibetan_relations_during_the_M...\n",
            "3      v2.0  {'title': 'IPod', 'paragraphs': [{'qas': [{'qu...\n",
            "4      v2.0  {'title': 'The_Legend_of_Zelda:_Twilight_Princ...\n",
            "..      ...                                                ...\n",
            "437    v2.0  {'title': 'Infection', 'paragraphs': [{'qas': ...\n",
            "438    v2.0  {'title': 'Hunting', 'paragraphs': [{'qas': [{...\n",
            "439    v2.0  {'title': 'Kathmandu', 'paragraphs': [{'qas': ...\n",
            "440    v2.0  {'title': 'Myocardial_infarction', 'paragraphs...\n",
            "441    v2.0  {'title': 'Matter', 'paragraphs': [{'qas': [{'...\n",
            "\n",
            "[442 rows x 2 columns]\n",
            "   version                                               data\n",
            "0     v2.0  {'title': 'Normans', 'paragraphs': [{'qas': [{...\n",
            "1     v2.0  {'title': 'Computational_complexity_theory', '...\n",
            "2     v2.0  {'title': 'Southern_California', 'paragraphs':...\n",
            "3     v2.0  {'title': 'Sky_(United_Kingdom)', 'paragraphs'...\n",
            "4     v2.0  {'title': 'Victoria_(Australia)', 'paragraphs'...\n",
            "5     v2.0  {'title': 'Huguenot', 'paragraphs': [{'qas': [...\n",
            "6     v2.0  {'title': 'Steam_engine', 'paragraphs': [{'qas...\n",
            "7     v2.0  {'title': 'Oxygen', 'paragraphs': [{'qas': [{'...\n",
            "8     v2.0  {'title': '1973_oil_crisis', 'paragraphs': [{'...\n",
            "9     v2.0  {'title': 'European_Union_law', 'paragraphs': ...\n",
            "10    v2.0  {'title': 'Amazon_rainforest', 'paragraphs': [...\n",
            "11    v2.0  {'title': 'Ctenophora', 'paragraphs': [{'qas':...\n",
            "12    v2.0  {'title': 'Fresno,_California', 'paragraphs': ...\n",
            "13    v2.0  {'title': 'Packet_switching', 'paragraphs': [{...\n",
            "14    v2.0  {'title': 'Black_Death', 'paragraphs': [{'qas'...\n",
            "15    v2.0  {'title': 'Geology', 'paragraphs': [{'qas': [{...\n",
            "16    v2.0  {'title': 'Pharmacy', 'paragraphs': [{'qas': [...\n",
            "17    v2.0  {'title': 'Civil_disobedience', 'paragraphs': ...\n",
            "18    v2.0  {'title': 'Construction', 'paragraphs': [{'qas...\n",
            "19    v2.0  {'title': 'Private_school', 'paragraphs': [{'q...\n",
            "20    v2.0  {'title': 'Harvard_University', 'paragraphs': ...\n",
            "21    v2.0  {'title': 'Jacksonville,_Florida', 'paragraphs...\n",
            "22    v2.0  {'title': 'Economic_inequality', 'paragraphs':...\n",
            "23    v2.0  {'title': 'University_of_Chicago', 'paragraphs...\n",
            "24    v2.0  {'title': 'Yuan_dynasty', 'paragraphs': [{'qas...\n",
            "25    v2.0  {'title': 'Immune_system', 'paragraphs': [{'qa...\n",
            "26    v2.0  {'title': 'Intergovernmental_Panel_on_Climate_...\n",
            "27    v2.0  {'title': 'Prime_number', 'paragraphs': [{'qas...\n",
            "28    v2.0  {'title': 'Rhine', 'paragraphs': [{'qas': [{'q...\n",
            "29    v2.0  {'title': 'Scottish_Parliament', 'paragraphs':...\n",
            "30    v2.0  {'title': 'Islamism', 'paragraphs': [{'qas': [...\n",
            "31    v2.0  {'title': 'Imperialism', 'paragraphs': [{'qas'...\n",
            "32    v2.0  {'title': 'Warsaw', 'paragraphs': [{'qas': [{'...\n",
            "33    v2.0  {'title': 'French_and_Indian_War', 'paragraphs...\n",
            "34    v2.0  {'title': 'Force', 'paragraphs': [{'qas': [{'q...\n"
          ]
        }
      ],
      "source": [
        "# import data from github repository\n",
        "train = pd.read_json('AML_project2/train-v2.0.json')\n",
        "val = pd.read_json('AML_project2/dev-v2.0.json')\n",
        "print(train)\n",
        "print(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNVeGouteeE5"
      },
      "source": [
        "This shows the structure of the json file, it has title, which is the topic, then the questions, the answers to those questions and the id of the questions. In the datasets, the questions and answers are organised under different topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxM8Lhiscy7a",
        "outputId": "a382bcb6-dec7-42f0-ad39-8d054734a03f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'qas': [{'question': 'When did Beyonce start becoming popular?',\n",
              "    'id': '56be85543aeaaa14008c9063',\n",
              "    'answers': [{'text': 'in the late 1990s', 'answer_start': 269}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'What areas did Beyonce compete in when she was growing up?',\n",
              "    'id': '56be85543aeaaa14008c9065',\n",
              "    'answers': [{'text': 'singing and dancing', 'answer_start': 207}],\n",
              "    'is_impossible': False},\n",
              "   {'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
              "    'id': '56be85543aeaaa14008c9066',\n",
              "    'answers': [{'text': '2003', 'answer_start': 526}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'In what city and state did Beyonce  grow up? ',\n",
              "    'id': '56bf6b0f3aeaaa14008c9601',\n",
              "    'answers': [{'text': 'Houston, Texas', 'answer_start': 166}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'In which decade did Beyonce become famous?',\n",
              "    'id': '56bf6b0f3aeaaa14008c9602',\n",
              "    'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'In what R&B group was she the lead singer?',\n",
              "    'id': '56bf6b0f3aeaaa14008c9603',\n",
              "    'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'What album made her a worldwide known artist?',\n",
              "    'id': '56bf6b0f3aeaaa14008c9604',\n",
              "    'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
              "    'is_impossible': False},\n",
              "   {'question': \"Who managed the Destiny's Child group?\",\n",
              "    'id': '56bf6b0f3aeaaa14008c9605',\n",
              "    'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'When did Beyoncé rise to fame?',\n",
              "    'id': '56d43c5f2ccc5a1400d830a9',\n",
              "    'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
              "    'is_impossible': False},\n",
              "   {'question': \"What role did Beyoncé have in Destiny's Child?\",\n",
              "    'id': '56d43c5f2ccc5a1400d830aa',\n",
              "    'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'What was the first album Beyoncé released as a solo artist?',\n",
              "    'id': '56d43c5f2ccc5a1400d830ab',\n",
              "    'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'When did Beyoncé release Dangerously in Love?',\n",
              "    'id': '56d43c5f2ccc5a1400d830ac',\n",
              "    'answers': [{'text': '2003', 'answer_start': 526}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'How many Grammy awards did Beyoncé win for her first solo album?',\n",
              "    'id': '56d43c5f2ccc5a1400d830ad',\n",
              "    'answers': [{'text': 'five', 'answer_start': 590}],\n",
              "    'is_impossible': False},\n",
              "   {'question': \"What was Beyoncé's role in Destiny's Child?\",\n",
              "    'id': '56d43ce42ccc5a1400d830b4',\n",
              "    'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
              "    'is_impossible': False},\n",
              "   {'question': \"What was the name of Beyoncé's first solo album?\",\n",
              "    'id': '56d43ce42ccc5a1400d830b5',\n",
              "    'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
              "    'is_impossible': False}],\n",
              "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "trainingCol = train.columns\n",
        "trainingCol\n",
        "train.iloc[0, 1][\"paragraphs\"][:1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO8K--pQMrOE",
        "outputId": "8dab07db-3e47-46b8-ca64-5fb98747e9d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'qas': [{'question': \"What was Frédéric's nationalities?\",\n",
              "    'id': '56cbd2356d243a140015ed66',\n",
              "    'answers': [{'text': 'Polish and French', 'answer_start': 182}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'In what era was Frédéric active in?',\n",
              "    'id': '56cbd2356d243a140015ed67',\n",
              "    'answers': [{'text': 'Romantic era', 'answer_start': 276}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'For what instrument did Frédéric write primarily for?',\n",
              "    'id': '56cbd2356d243a140015ed68',\n",
              "    'answers': [{'text': 'solo piano', 'answer_start': 318}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'In what area was Frédéric born in?',\n",
              "    'id': '56cbd2356d243a140015ed69',\n",
              "    'answers': [{'text': 'Duchy of Warsaw', 'answer_start': 559}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'At what age did Frédéric depart from Poland?',\n",
              "    'id': '56cbd2356d243a140015ed6a',\n",
              "    'answers': [{'text': '20', 'answer_start': 777}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'What year was Chopin born?',\n",
              "    'id': '56ce0a3762d2951400fa69d6',\n",
              "    'answers': [{'text': '1810', 'answer_start': 113}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'What era was Chopin active during?',\n",
              "    'id': '56ce0a3762d2951400fa69d7',\n",
              "    'answers': [{'text': 'Romantic era', 'answer_start': 276}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'Where did Chopin grow up?',\n",
              "    'id': '56ce0a3762d2951400fa69d8',\n",
              "    'answers': [{'text': 'Warsaw', 'answer_start': 568}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'What instrument did he mostly compose for?',\n",
              "    'id': '56ce0a3762d2951400fa69d9',\n",
              "    'answers': [{'text': 'solo piano', 'answer_start': 318}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'At what age did Chopin  leave Poland?',\n",
              "    'id': '56ce0a3762d2951400fa69da',\n",
              "    'answers': [{'text': '20', 'answer_start': 777}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'When did Chopin die?',\n",
              "    'id': '56cf54a2aab44d1400b89006',\n",
              "    'answers': [{'text': '17 October 1849', 'answer_start': 120}],\n",
              "    'is_impossible': False},\n",
              "   {'question': \"What was Chopin's full name?\",\n",
              "    'id': '56cf54a2aab44d1400b89008',\n",
              "    'answers': [{'text': 'Fryderyk Franciszek Chopin', 'answer_start': 143}],\n",
              "    'is_impossible': False},\n",
              "   {'question': \"The majority of Chopin's compositions were for what instrument?\",\n",
              "    'id': '56cf54a2aab44d1400b89009',\n",
              "    'answers': [{'text': 'solo piano', 'answer_start': 318}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'Chopin was active during what era?',\n",
              "    'id': '56cf54a2aab44d1400b8900a',\n",
              "    'answers': [{'text': 'Romantic era', 'answer_start': 276}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'In what year was Chopin born?',\n",
              "    'id': '56d1ca30e7d4791d009021a7',\n",
              "    'answers': [{'text': '1810', 'answer_start': 113}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'In what city was Chopin born and raised?',\n",
              "    'id': '56d1ca30e7d4791d009021a8',\n",
              "    'answers': [{'text': 'Warsaw', 'answer_start': 568}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'How old was Chopin when he left Poland?',\n",
              "    'id': '56d1ca30e7d4791d009021a9',\n",
              "    'answers': [{'text': '20', 'answer_start': 777}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'In what era of music did Chopin compose?',\n",
              "    'id': '56d1ca30e7d4791d009021aa',\n",
              "    'answers': [{'text': 'Romantic', 'answer_start': 276}],\n",
              "    'is_impossible': False},\n",
              "   {'question': 'What year did Chopin die?',\n",
              "    'id': '56d1ca30e7d4791d009021ab',\n",
              "    'answers': [{'text': '1849', 'answer_start': 131}],\n",
              "    'is_impossible': False}],\n",
              "  'context': 'Frédéric François Chopin (/ˈʃoʊpæn/; French pronunciation: \\u200b[fʁe.de.ʁik fʁɑ̃.swa ʃɔ.pɛ̃]; 22 February or 1 March 1810 – 17 October 1849), born Fryderyk Franciszek Chopin,[n 1] was a Polish and French (by citizenship and birth of father) composer and a virtuoso pianist of the Romantic era, who wrote primarily for the solo piano. He gained and has maintained renown worldwide as one of the leading musicians of his era, whose \"poetic genius was based on a professional technique that was without equal in his generation.\" Chopin was born in what was then the Duchy of Warsaw, and grew up in Warsaw, which after 1815 became part of Congress Poland. A child prodigy, he completed his musical education and composed his earlier works in Warsaw before leaving Poland at the age of 20, less than a month before the outbreak of the November 1830 Uprising.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "##title, paragraphs and context\n",
        "train.iloc[1][\"data\"][\"paragraphs\"][:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DV2gMHQYK3pb"
      },
      "outputs": [],
      "source": [
        "for i in trainingCol[0:10]:\n",
        "  train.iloc[0, 1][\"title\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE3GL4cvzi1P"
      },
      "source": [
        "### Count the number of data we have in both the training and validation sets.\n",
        "The size of the dataset is quite small, but the partition between the training and validation set is good (since always we have a traning set much bigger than the validation set). Often the dataset is first split in traning and test set, since the validation set is obtained by further splitting the training set. In this case is it required to get the test set from the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZmM72m9w-6h",
        "outputId": "25ab12a4-3513-494a-ee46-9d08740eaa5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories in the training set: 442\n",
            "Categories in the validation set: 35 \n",
            "\n",
            "Questions in the training set: 130319\n",
            "Questions in the validation set: 11873 \n",
            "\n",
            "Answers in the training set: 86821\n",
            "Answers in the validation set: 20302 \n",
            "\n",
            "Total data in training set (Q + A): 217140\n",
            "Total data in validation set (Q + A): 32175 \n",
            "\n",
            "Total data in dataset (Q + A): 249315 \n",
            "\n",
            "Partition dataset:\n",
            "\t Training set: 87 %.\n",
            "\t Validation set: 13 %.\n"
          ]
        }
      ],
      "source": [
        "def count_data(series):\n",
        "  nr_categories = 0\n",
        "  nr_questions = 0\n",
        "  nr_answers = 0\n",
        "\n",
        "  for category in series:\n",
        "    nr_categories += 1\n",
        "    paragraphs = category.get('paragraphs', [])\n",
        "    for para in paragraphs:\n",
        "      qas_list = para.get('qas', [])\n",
        "      nr_questions += len(qas_list)\n",
        "      for qas in qas_list:\n",
        "        answers = qas.get('answers', [])\n",
        "        nr_answers += len(answers)\n",
        "  return nr_categories, nr_questions, nr_answers\n",
        "\n",
        "count_train = count_data(train['data'])\n",
        "count_val = count_data(val['data']);\n",
        "\n",
        "print(\"Categories in the training set:\", count_train[0])\n",
        "print(\"Categories in the validation set:\", count_val[0], \"\\n\")\n",
        "print(\"Questions in the training set:\", count_train[1])\n",
        "print(\"Questions in the validation set:\", count_val[1], \"\\n\")\n",
        "print(\"Answers in the training set:\", count_train[2])\n",
        "print(\"Answers in the validation set:\", count_val[2], \"\\n\")\n",
        "\n",
        "print('Total data in training set (Q + A):', count_train[1] + count_train[2])\n",
        "print('Total data in validation set (Q + A):', count_val[1] + count_val[2], \"\\n\")\n",
        "\n",
        "print('Total data in dataset (Q + A):', count_train[1] + count_train[2] + count_val[1] + count_val[2], \"\\n\")\n",
        "\n",
        "print('Partition dataset:')\n",
        "print('\\t Training set:',round((count_train[1] + count_train[2])/(count_train[1] + count_train[2] + count_val[1] + count_val[2])*100) , '%.')\n",
        "print('\\t Validation set:',round((count_val[1] + count_val[2])/(count_train[1] + count_train[2] + count_val[1] + count_val[2])*100) , '%.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp8PDmnIPjbp"
      },
      "source": [
        "Made some edits to the dataset from the previos files to factor in for data that was missing in each of the different columns, just so that the lengths would be the same and there won't be answers assigned to the wrong questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h1RdvPffUooG"
      },
      "outputs": [],
      "source": [
        "#through this i want to separate the question and answer text\n",
        "\n",
        "def input_vocabulary(data):\n",
        "  questionsTrainList = []\n",
        "  answersTrainList = []\n",
        "  contextTrainList = []\n",
        "  answer_startList = []\n",
        "\n",
        "  for category in data:\n",
        "      paragraphs = category.get('paragraphs', [])\n",
        "      #print(paragraphs)\n",
        "      for para in paragraphs:\n",
        "        context_list = para.get('context', [])\n",
        "        qas_list = para.get('qas', [])\n",
        "        for qa in qas_list:\n",
        "          # set lower case\n",
        "          question = qa.get('question', '').lower()\n",
        "          # remove punctuation, split '/' and numbers and words with numbers\n",
        "          clean_question = re.sub(r'[^\\w\\s/]', '', question)\n",
        "          clean_question = re.sub(r'/', ' ', clean_question)\n",
        "          clean_question = re.sub(r'\\b(?:\\w*\\d\\w*|\\d+)\\b', '', clean_question)\n",
        "          clean_question = re.sub(r'_', '', clean_question)\n",
        "          questionsTrainList.append(clean_question)\n",
        "          contextTrainList.append(context_list) ##through this i get the context of each topic\n",
        "          answers = qa.get('answers',  []) ### because there were empty answer, this was taken care of by putting it as None as the length of the question and answer has to equal each other\n",
        "\n",
        "          if answers == []:\n",
        "            text = None\n",
        "            ansStart = None\n",
        "            answersTrainList.append(text)\n",
        "            answer_startList.append(ansStart)\n",
        "          else:\n",
        "            for ans in answers:\n",
        "              text = ans.get('text',  [])\n",
        "              #print(answers)\n",
        "              answersTrainList.append(text)\n",
        "              ansStart = ans.get('answer_start', [])\n",
        "              answer_startList.append(ansStart)\n",
        "  return questionsTrainList, answersTrainList, contextTrainList, answer_startList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8YU0KnP68s28"
      },
      "outputs": [],
      "source": [
        "##calls the training set function\n",
        "questionsTrainList, answersTrainList, contextTrainList, answerStartTrainList = input_vocabulary(train['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZqoYCB-VUgh",
        "outputId": "7b872afb-509f-4983-8a07-24a52d3a88e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what field of study has a variety of unusual contexts\n",
            "None\n",
            "The term \"matter\" is used throughout physics in a bewildering variety of contexts: for example, one refers to \"condensed matter physics\", \"elementary matter\", \"partonic\" matter, \"dark\" matter, \"anti\"-matter, \"strange\" matter, and \"nuclear\" matter. In discussions of matter and antimatter, normal matter has been referred to by Alfvén as koinomatter (Gk. common matter). It is fair to say that in physics, there is no broad consensus as to a general definition of matter, and the term \"matter\" usually is used in conjunction with a specifying modifier.\n",
            "None\n",
            "\n",
            "130319\n",
            "130319\n",
            "130319\n",
            "130319\n"
          ]
        }
      ],
      "source": [
        "##checking that the right question, answer, context is assigned correctly by viewing the last index in the dataframe\n",
        "print(f\"{questionsTrainList[130318]}\")\n",
        "print(f\"{answersTrainList[130318]}\")\n",
        "print(f\"{contextTrainList[130318]}\")\n",
        "print(f\"{answerStartTrainList[130318]}\")\n",
        "\n",
        "print()\n",
        "##checking that they are all the same lengths so that there is no issue with tokenising\n",
        "print(f\"{len(questionsTrainList)}\")\n",
        "print(f\"{len(answersTrainList)}\")\n",
        "print(f\"{len(contextTrainList)}\")\n",
        "print(f\"{len(answerStartTrainList)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpCA_8IqKW3r"
      },
      "source": [
        "put it in a dataframe for easier analysis and visualisation later on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LnRZtPoSI8yo",
        "outputId": "fb6934f0-c36c-4cc9-ba4c-fe413e57e046"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Question               Answer  \\\n",
              "0            when did beyonce start becoming popular    in the late 1990s   \n",
              "1  what areas did beyonce compete in when she was...  singing and dancing   \n",
              "2  when did beyonce leave destinys child and beco...                 2003   \n",
              "3       in what city and state did beyonce  grow up        Houston, Texas   \n",
              "4          in which decade did beyonce become famous           late 1990s   \n",
              "\n",
              "   Answer_Start                                            Context  \n",
              "0         269.0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  \n",
              "1         207.0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  \n",
              "2         526.0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  \n",
              "3         166.0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  \n",
              "4         276.0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13ffea6c-6025-459c-ac5f-d3c94b7c76b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Answer_Start</th>\n",
              "      <th>Context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when did beyonce start becoming popular</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>269.0</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>207.0</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when did beyonce leave destinys child and beco...</td>\n",
              "      <td>2003</td>\n",
              "      <td>526.0</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in what city and state did beyonce  grow up</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>166.0</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in which decade did beyonce become famous</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>276.0</td>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13ffea6c-6025-459c-ac5f-d3c94b7c76b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13ffea6c-6025-459c-ac5f-d3c94b7c76b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13ffea6c-6025-459c-ac5f-d3c94b7c76b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-756b213f-2ce6-41e2-9db0-4431a1454646\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-756b213f-2ce6-41e2-9db0-4431a1454646')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-756b213f-2ce6-41e2-9db0-4431a1454646 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "data = {'Question': questionsTrainList, 'Answer': answersTrainList, 'Answer_Start': answerStartTrainList, 'Context': contextTrainList}\n",
        "trainingData = pd.DataFrame(data)\n",
        "trainingData.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsi9tUf1fan6"
      },
      "source": [
        "<br><br>\n",
        "repeating the same process for the validation set because the the lengths of the column gave different answers when calling it with the train function above. Main difference here is where the contextList is placed in the dataset.\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zcLhKpGxfpQ2"
      },
      "outputs": [],
      "source": [
        "#through this i want to separate the question and answer text\n",
        "questionsValList = []\n",
        "answersValList = []\n",
        "contextValList = []\n",
        "answerStartValList = []\n",
        "\n",
        "for category in val['data']:\n",
        "    paragraphs = category.get('paragraphs', [])\n",
        "    #print(paragraphs)\n",
        "    for para in paragraphs:\n",
        "      context_list = para.get('context', [])\n",
        "      qas_list = para.get('qas', [])\n",
        "      for qa in qas_list:\n",
        "        # set lower case\n",
        "        question = qa.get('question', '').lower()\n",
        "        if question is None:\n",
        "          text = \"None\"\n",
        "          questionsValList.append(text)\n",
        "        else:\n",
        "          # remove punctuation, split '/' and numbers and words with numbers\n",
        "          clean_question = re.sub(r'[^\\w\\s/]', '', question)\n",
        "          clean_question = re.sub(r'/', ' ', clean_question)\n",
        "          clean_question = re.sub(r'\\b(?:\\w*\\d\\w*|\\d+)\\b', '', clean_question)\n",
        "          clean_question = re.sub(r'_', '', clean_question)\n",
        "          answers = qa.get('answers',  []) ### because there were empty answer, this was taken care of by putting it as None as the length of the question and answer has to equal each other\n",
        "          for ans in answers:\n",
        "            text = ans.get('text',  [])\n",
        "            #print(answers)\n",
        "            answersValList.append(text)\n",
        "            contextValList.append(context_list) ##through this i get the context of each topic\n",
        "            ansStart = ans.get('answer_start', [])\n",
        "            answerStartValList.append(ansStart)\n",
        "            questionsValList.append(clean_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W31l-tZ2gdxK",
        "outputId": "4ca3d0cf-340c-45c5-ecc2-b1b9d47828a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20302\n",
            "20302\n",
            "20302\n",
            "20302\n"
          ]
        }
      ],
      "source": [
        "##checking that they are all the same lengths so that there is no issue with tokenising\n",
        "print(f\"{len(questionsValList)}\")\n",
        "print(f\"{len(answersValList)}\")\n",
        "print(f\"{len(contextValList)}\")\n",
        "print(f\"{len(answerStartValList)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "blcyGGgXdre8",
        "outputId": "e9f31778-b930-4893-ff3a-92a6eabaaa87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Question                   Answer  Answer_Start  \\\n",
              "0  in what country is normandy located                   France           159   \n",
              "1  in what country is normandy located                   France           159   \n",
              "2  in what country is normandy located                   France           159   \n",
              "3  in what country is normandy located                   France           159   \n",
              "4    when were the normans in normandy  10th and 11th centuries            94   \n",
              "\n",
              "                                             Context  \n",
              "0  The Normans (Norman: Nourmands; French: Norman...  \n",
              "1  The Normans (Norman: Nourmands; French: Norman...  \n",
              "2  The Normans (Norman: Nourmands; French: Norman...  \n",
              "3  The Normans (Norman: Nourmands; French: Norman...  \n",
              "4  The Normans (Norman: Nourmands; French: Norman...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7dd81a8-002f-4fde-b511-78c39e121271\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Answer_Start</th>\n",
              "      <th>Context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in what country is normandy located</td>\n",
              "      <td>France</td>\n",
              "      <td>159</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in what country is normandy located</td>\n",
              "      <td>France</td>\n",
              "      <td>159</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in what country is normandy located</td>\n",
              "      <td>France</td>\n",
              "      <td>159</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in what country is normandy located</td>\n",
              "      <td>France</td>\n",
              "      <td>159</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>when were the normans in normandy</td>\n",
              "      <td>10th and 11th centuries</td>\n",
              "      <td>94</td>\n",
              "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7dd81a8-002f-4fde-b511-78c39e121271')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7dd81a8-002f-4fde-b511-78c39e121271 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7dd81a8-002f-4fde-b511-78c39e121271');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cddf0e86-b027-48ac-b2de-80da924b7bb4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cddf0e86-b027-48ac-b2de-80da924b7bb4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cddf0e86-b027-48ac-b2de-80da924b7bb4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "##put it in a dataframe for easier analysis and visualisation later on\n",
        "data = {'Question': questionsValList, 'Answer': answersValList, 'Answer_Start': answerStartValList, 'Context': contextValList}\n",
        "valData = pd.DataFrame(data)\n",
        "valData.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEGHusROQyCO"
      },
      "source": [
        "added the training set and the validation set into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VSHQtkJyF3Zv"
      },
      "outputs": [],
      "source": [
        "trainingData = trainingData.iloc[:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfjfRrif_I3s",
        "outputId": "5073dfdf-31d9-4540-ee37-c52e50bf2d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ed826c85edda>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  trainingData['Label'] = trainingData['Answer'].map(ansToLabel)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          0\n",
              "1          1\n",
              "2          2\n",
              "3          3\n",
              "4          4\n",
              "        ... \n",
              "1995    1351\n",
              "1996    1353\n",
              "1997    1354\n",
              "1998    1355\n",
              "1999    1356\n",
              "Name: Label, Length: 2000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "##assiging a label to each of the answers\n",
        "ansToLabel = {answer: idx for idx, answer in enumerate(trainingData['Answer'].unique())}\n",
        "trainingData['Label'] = trainingData['Answer'].map(ansToLabel)\n",
        "trainingData['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUeavnIhGXgU",
        "outputId": "41ac2a37-6d99-4ef3-dc2e-29fd2dd355da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-c354472468fe>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  trainingData.dropna(inplace =True)\n"
          ]
        }
      ],
      "source": [
        "##dropping none type since the tokeniser won't accept nonetype\n",
        "trainingData.dropna(inplace =True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKPWd5oa-Z67",
        "outputId": "88e1e861-baf9-4287-9291-187563c5647e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape checks:\n",
            "X_train: (1400,) X_val: (600,)\n",
            "y_train: (1400,) y_val: (600,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(trainingData['Question'], trainingData['Answer'], test_size = 0.3, random_state = 7)\n",
        "print(f'\\nShape checks:\\nX_train: {X_train.shape} X_val: {X_val.shape}\\ny_train: {y_train.shape} y_val: {y_val.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sJItyXTYJB_n"
      },
      "outputs": [],
      "source": [
        "##had to reset the index because after the split, they are not in order\n",
        "X_train.reset_index(drop=True, inplace = True)\n",
        "X_val.reset_index(drop=True, inplace = True)\n",
        "y_train.reset_index(drop=True, inplace = True)\n",
        "y_val.reset_index(drop=True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJv4DVs-JsZz",
        "outputId": "0a3ae678-428c-4c99-ba58-40b290b56fc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=1400, step=1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X_train.index\n",
        "y_train.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZBxWdyxtpZAd",
        "outputId": "55b61c1b-0533-4b5a-dafc-e28aa6afacb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Question  \\\n",
              "0     who did a work for italian television about ch...   \n",
              "1              on what magazine was she the cover model   \n",
              "2     how many dates did the mrs carter show world t...   \n",
              "3     totaling worldwide how many records as beyonce...   \n",
              "4     what organization discovered that the advertis...   \n",
              "...                                                 ...   \n",
              "1395                where was the linggu temple located   \n",
              "1396                  how does alice jones describe her   \n",
              "1397               what title did complex award beyoncé   \n",
              "1398  when was the international chopin piano compet...   \n",
              "1399  for which decade did beyonce have more top ten...   \n",
              "\n",
              "                                     Answer  \n",
              "0     Angelo Bozzolini and Roberto Prosseda  \n",
              "1                                     Vogue  \n",
              "2                                       132  \n",
              "3                               118 million  \n",
              "4                                   NetBase  \n",
              "...                                     ...  \n",
              "1395                                Nanjing  \n",
              "1396                  she's almost too good  \n",
              "1397      Hottest Female Singer of All Time  \n",
              "1398                                   1927  \n",
              "1399                                  2000s  \n",
              "\n",
              "[1400 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-573b3b1d-a0c4-47bc-9cee-c2f5bac0ac0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>who did a work for italian television about ch...</td>\n",
              "      <td>Angelo Bozzolini and Roberto Prosseda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>on what magazine was she the cover model</td>\n",
              "      <td>Vogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how many dates did the mrs carter show world t...</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>totaling worldwide how many records as beyonce...</td>\n",
              "      <td>118 million</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what organization discovered that the advertis...</td>\n",
              "      <td>NetBase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>where was the linggu temple located</td>\n",
              "      <td>Nanjing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>how does alice jones describe her</td>\n",
              "      <td>she's almost too good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>what title did complex award beyoncé</td>\n",
              "      <td>Hottest Female Singer of All Time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>when was the international chopin piano compet...</td>\n",
              "      <td>1927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>for which decade did beyonce have more top ten...</td>\n",
              "      <td>2000s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-573b3b1d-a0c4-47bc-9cee-c2f5bac0ac0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-573b3b1d-a0c4-47bc-9cee-c2f5bac0ac0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-573b3b1d-a0c4-47bc-9cee-c2f5bac0ac0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8e55aad-70bf-4752-90c5-202ad983e4e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8e55aad-70bf-4752-90c5-202ad983e4e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8e55aad-70bf-4752-90c5-202ad983e4e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "##adding the df back together because i want to combine the question and ans, since the training is going to be done with classification\n",
        "data = {'Question': X_train, 'Answer': y_train}\n",
        "trainDF = pd.DataFrame(data)\n",
        "trainDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "adZpCNeAQ9BI",
        "outputId": "e8fb3d2c-5436-45a8-8483-599ccd2a19ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Question  \\\n",
              "0    what did chopin write on the box of letters fr...   \n",
              "1    for whose benefit was the first of these conce...   \n",
              "2    beyonce tied who for most number one singles b...   \n",
              "3                beyonces familys company name is what   \n",
              "4    what apple program is used to communicate betw...   \n",
              "..                                                 ...   \n",
              "595  what was the first generation of ipod classic ...   \n",
              "596  who did beyonce participate with in the hope f...   \n",
              "597                when did beyoncé endorse on march     \n",
              "598  who inspired beyoncé to take control of her ca...   \n",
              "599  what was recognized about chopin from his musi...   \n",
              "\n",
              "                                  Answer  \n",
              "0                             My tragedy  \n",
              "1                       Harriet Smithson  \n",
              "2                           Mariah Carey  \n",
              "3                     Beyond Productions  \n",
              "4                                 iTunes  \n",
              "..                                   ...  \n",
              "595                       5th generation  \n",
              "596       George Clooney and Wyclef Jean  \n",
              "597                    same sex marriage  \n",
              "598                              Madonna  \n",
              "599  qualities as a pianist and composer  \n",
              "\n",
              "[600 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2e4e6aa-3418-4283-a88c-d780bc28b784\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what did chopin write on the box of letters fr...</td>\n",
              "      <td>My tragedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>for whose benefit was the first of these conce...</td>\n",
              "      <td>Harriet Smithson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>beyonce tied who for most number one singles b...</td>\n",
              "      <td>Mariah Carey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>beyonces familys company name is what</td>\n",
              "      <td>Beyond Productions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what apple program is used to communicate betw...</td>\n",
              "      <td>iTunes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>what was the first generation of ipod classic ...</td>\n",
              "      <td>5th generation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>who did beyonce participate with in the hope f...</td>\n",
              "      <td>George Clooney and Wyclef Jean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>when did beyoncé endorse on march</td>\n",
              "      <td>same sex marriage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>who inspired beyoncé to take control of her ca...</td>\n",
              "      <td>Madonna</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>what was recognized about chopin from his musi...</td>\n",
              "      <td>qualities as a pianist and composer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2e4e6aa-3418-4283-a88c-d780bc28b784')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2e4e6aa-3418-4283-a88c-d780bc28b784 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2e4e6aa-3418-4283-a88c-d780bc28b784');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86630213-03ce-47b6-babc-082eebb41a5c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86630213-03ce-47b6-babc-082eebb41a5c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86630213-03ce-47b6-babc-082eebb41a5c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "data = {'Question': X_val, 'Answer': y_val}\n",
        "testDF = pd.DataFrame(data)\n",
        "testDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXTGpZHpCXZD"
      },
      "source": [
        "Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kQnVRLw2Cnaa"
      },
      "outputs": [],
      "source": [
        "from tokenizers.processors import BertProcessing\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from pathlib import Path\n",
        "\n",
        "# Initialize a tokenizer\n",
        "#tokenizer = ByteLevelBPETokenizer()\n",
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "# Customize training\n",
        "#tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\"\",\"\",\"\",\"\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nB1Qr-kuCJAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c8bdda-d008-43cd-ea5e-eaf10ed675c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "#     (\"\", tokenizer.token_to_id(\"\")),\n",
        "#     (\"\", tokenizer.token_to_id(\"\")),\n",
        "# )\n",
        "# tokenizer.enable_truncation(max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ne3LPqpPFPeU"
      },
      "outputs": [],
      "source": [
        "#print(\"vocabulary size: \", len(tokenizer.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rn0CFLHuO3YU"
      },
      "outputs": [],
      "source": [
        "tokenized_texts = tokenizer(questionsTrainList, answersTrainList, return_tensors='pt', padding=True, truncation=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18spiIYrDgdY"
      },
      "source": [
        " training from scratch, so only the config file is done from the roberta model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMRQTYc22AWR"
      },
      "source": [
        "# 2. Training Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWzoO-NntD1c"
      },
      "source": [
        "The traditional methods for question and answer based system is based on using concepts such as keyword matching, TF-IDF, or word embeddings to get and select appropriate responses based on matching patterns or keywords. The below model is a logistic regession model, that is trained on our training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLHEJ60m2FSW"
      },
      "source": [
        "## Train the model to perform the question and answering task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4DWeJZuYDGDD"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaConfig, RobertaForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "# ##creating tokeniser\n",
        "# from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
        "# import torch\n",
        "\n",
        "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "#Initializing a RoBERTa configuration\n",
        "config = RobertaConfig(\n",
        " vocab_size=32_000,\n",
        " max_position_embeddings=514,\n",
        " num_attention_heads=12,\n",
        " num_hidden_layers=12,\n",
        " type_vocab_size=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rilWhLSsC9DA"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Uec1nJ3DvGo",
        "outputId": "d44a652b-5262-4a6a-b2b0-cd3ffdf38052"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110651648"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.num_parameters() #110651648\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NM-aWm5_Fd03"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "x3mrsT0nQQ08"
      },
      "outputs": [],
      "source": [
        "    # inputs = tokenizer(\n",
        "    #     questions,\n",
        "    #     examples[\"Context\"],\n",
        "    #     max_length=384,\n",
        "    #     truncation=\"only_second\",\n",
        "    #     return_offsets_mapping=True,\n",
        "    #     padding=\"max_length\",\n",
        "    # )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2NMiwbqLSlc"
      },
      "source": [
        "Inserting model built from scratch here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH64Dg-nObG8"
      },
      "source": [
        "!pip install transformers==2.11.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate>=0.20.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMfSfRep1xSx",
        "outputId": "63be3d67-0c17-4689-f712-a2403f5a96c0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKiatsaY2DSh",
        "outputId": "f2a6e329-343a-48e7-af9d-32bb2a8414f3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tdcVAHazFe-y"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"content/model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_texts,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "bmt8XJ6aHYco",
        "outputId": "1c8d99a3-f16e-4523-909c-658ed8500597"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Invalid key. Only three types of key are available: (1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrng_to_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;34m\"Invalid key. Only three types of key are available: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;34m\"(1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Invalid key. Only three types of key are available: (1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.'"
          ]
        }
      ],
      "source": [
        "##need to fix this error\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FIk4tbwmuZq8"
      },
      "outputs": [],
      "source": [
        "##reducing the size of the dataset as it crashes the session training with the whole dataset\n",
        "# newdf = newdf.iloc[:2000]\n",
        "# newdf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3SUMXjGetjIi"
      },
      "outputs": [],
      "source": [
        "# data = {'Question': newdf['Question'], 'Answer': newdf['Answer']}\n",
        "# df = pd.DataFrame(data )\n",
        "#newdf.dropna(inplace = True)\n",
        "# ###changing the text data to numeric, so that it will be able to use the svm model\n",
        "# df['Question'] = tfidf_vectorizer.fit_transform(df['Question']).toarray()\n",
        "# df['Answer'] = tfidf_vectorizer.fit_transform(df['Answer']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import torch\n",
        "\n",
        "# # Assuming you have created your trainDf and valDf DataFrames with columns 'text' and 'label'\n",
        "# train_dataset = MyDataset(trainingData, tokenizer)  # Pass your tokenizer instance\n",
        "# val_dataset = MyDataset(valData, tokenizer)  # Pass your tokenizer instance\n",
        "# # Create a DatasetDict\n",
        "# datasets = DatasetDict({'train': train_dataset, 'validation': val_dataset})"
      ],
      "metadata": {
        "id": "JzmiRgoqsGqj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLSlhnc5KGKt"
      },
      "source": [
        "using TF-IDF and cosine similarity for the QA system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjsRCUmTJico"
      },
      "source": [
        "##Logistic Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGzxqonZKHlt"
      },
      "source": [
        "using a logistic regession model for the QA system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "C_oqtrpQDR_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05282d72-b1ce-45ae-ce71-755db349f667"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          0\n",
              "1          1\n",
              "2          2\n",
              "3          3\n",
              "4          4\n",
              "        ... \n",
              "1995    1351\n",
              "1996    1353\n",
              "1997    1354\n",
              "1998    1355\n",
              "1999    1356\n",
              "Name: Label, Length: 2000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "##assiging a label to each of the answers\n",
        "ansToLabel = {answer: idx for idx, answer in enumerate(trainingData['Answer'].unique())}\n",
        "trainingData['Label'] = trainingData['Answer'].map(ansToLabel)\n",
        "trainingData['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zlhCV7aaDXmb"
      },
      "outputs": [],
      "source": [
        "#dataset is split into training and test dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(trainingData['Question'], trainingData['Label'], test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##had to reset the index because after the split, they are not in order\n",
        "X_train.reset_index(drop=True, inplace = True)\n",
        "X_val.reset_index(drop=True, inplace = True)\n",
        "y_train.reset_index(drop=True, inplace = True)\n",
        "y_val.reset_index(drop=True, inplace = True)"
      ],
      "metadata": {
        "id": "8JKrIJcItQeN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "PFEftgNCbxEn"
      },
      "outputs": [],
      "source": [
        "# Vectorize the training data using CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0Vvn0dGobzoG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "b487588a-fd28-477a-dcec-fa0867a49642"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=10000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Train a logistic regression classifier\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(X_train_vectorized, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ng136pR1a8z"
      },
      "source": [
        "# Evaluation of Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "v1C2KJsjdYa9"
      },
      "outputs": [],
      "source": [
        "##turn into numeric representation\n",
        "X_test_vectorized = vectorizer.transform(X_val)\n",
        "\n",
        "#getting the predictions\n",
        "predictions = lr.predict(X_test_vectorized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks0poMlSHskB"
      },
      "source": [
        "the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "7xWeHVbIEBPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d11d900-3eb4-40a9-81c9-df1abf3a7474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 9.5\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_val, predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "-xb1D9x6C2dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951c5a64-76d3-494c-deb9-ab190bc496e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         1\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         2\n",
            "          12       0.15      0.40      0.22         5\n",
            "          13       0.20      0.50      0.29         2\n",
            "          14       0.11      0.50      0.18         2\n",
            "          15       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         2\n",
            "          19       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         1\n",
            "          23       0.00      0.00      0.00         2\n",
            "          24       0.00      0.00      0.00         1\n",
            "          26       0.20      1.00      0.33         1\n",
            "          27       0.00      0.00      0.00         2\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         1\n",
            "          32       0.00      0.00      0.00         1\n",
            "          33       0.00      0.00      0.00         1\n",
            "          34       0.00      0.00      0.00         2\n",
            "          38       0.00      0.00      0.00         1\n",
            "          39       0.00      0.00      0.00         0\n",
            "          42       0.00      0.00      0.00         1\n",
            "          45       0.00      0.00      0.00         2\n",
            "          46       0.00      0.00      0.00         2\n",
            "          47       0.00      0.00      0.00         0\n",
            "          48       0.00      0.00      0.00         2\n",
            "          49       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         1\n",
            "          52       0.00      0.00      0.00         1\n",
            "          53       0.00      0.00      0.00         1\n",
            "          55       0.00      0.00      0.00         1\n",
            "          57       1.00      1.00      1.00         1\n",
            "          63       0.00      0.00      0.00         0\n",
            "          67       0.00      0.00      0.00         3\n",
            "          72       0.00      0.00      0.00         1\n",
            "          73       0.00      0.00      0.00         1\n",
            "          74       0.00      0.00      0.00         1\n",
            "          77       0.00      0.00      0.00         1\n",
            "          79       0.00      0.00      0.00         0\n",
            "          81       0.00      0.00      0.00         1\n",
            "          83       0.00      0.00      0.00         1\n",
            "          84       0.00      0.00      0.00         1\n",
            "          87       0.00      0.00      0.00         2\n",
            "          89       0.00      0.00      0.00         0\n",
            "          90       0.00      0.00      0.00         1\n",
            "          96       0.12      1.00      0.22         1\n",
            "          97       0.00      0.00      0.00         4\n",
            "          99       0.00      0.00      0.00         1\n",
            "         101       0.00      0.00      0.00         0\n",
            "         102       0.00      0.00      0.00         0\n",
            "         103       0.09      0.20      0.13         5\n",
            "         104       0.00      0.00      0.00         1\n",
            "         109       0.00      0.00      0.00         0\n",
            "         110       0.00      0.00      0.00         1\n",
            "         112       0.00      0.00      0.00         0\n",
            "         116       0.00      0.00      0.00         1\n",
            "         117       0.00      0.00      0.00         3\n",
            "         123       0.00      0.00      0.00         1\n",
            "         129       1.00      0.50      0.67         2\n",
            "         131       0.00      0.00      0.00         1\n",
            "         133       0.00      0.00      0.00         1\n",
            "         134       0.00      0.00      0.00         2\n",
            "         135       0.00      0.00      0.00         1\n",
            "         139       0.00      0.00      0.00         1\n",
            "         140       0.00      0.00      0.00         1\n",
            "         141       0.00      0.00      0.00         1\n",
            "         142       0.00      0.00      0.00         1\n",
            "         143       0.00      0.00      0.00         1\n",
            "         144       0.00      0.00      0.00         1\n",
            "         145       0.00      0.00      0.00         0\n",
            "         150       1.00      1.00      1.00         1\n",
            "         153       0.14      1.00      0.25         1\n",
            "         154       0.00      0.00      0.00         1\n",
            "         156       0.00      0.00      0.00         0\n",
            "         159       0.00      0.00      0.00         1\n",
            "         163       0.00      0.00      0.00         1\n",
            "         164       0.00      0.00      0.00         1\n",
            "         165       0.00      0.00      0.00         1\n",
            "         166       1.00      1.00      1.00         1\n",
            "         167       0.00      0.00      0.00         1\n",
            "         169       0.00      0.00      0.00         1\n",
            "         171       0.00      0.00      0.00         0\n",
            "         173       0.67      1.00      0.80         2\n",
            "         174       0.00      0.00      0.00         1\n",
            "         175       0.00      0.00      0.00         3\n",
            "         176       0.00      0.00      0.00         1\n",
            "         179       0.00      0.00      0.00         1\n",
            "         181       0.00      0.00      0.00         2\n",
            "         182       0.00      0.00      0.00         1\n",
            "         183       1.00      0.50      0.67         2\n",
            "         184       0.00      0.00      0.00         1\n",
            "         186       0.00      0.00      0.00         1\n",
            "         187       0.00      0.00      0.00         1\n",
            "         188       0.00      0.00      0.00         1\n",
            "         194       0.00      0.00      0.00         1\n",
            "         198       0.00      0.00      0.00         0\n",
            "         199       0.00      0.00      0.00         1\n",
            "         203       0.00      0.00      0.00         1\n",
            "         204       0.00      0.00      0.00         1\n",
            "         205       0.33      0.33      0.33         3\n",
            "         206       1.00      1.00      1.00         1\n",
            "         207       0.00      0.00      0.00         1\n",
            "         208       1.00      0.50      0.67         2\n",
            "         209       0.00      0.00      0.00         1\n",
            "         210       0.00      0.00      0.00         1\n",
            "         211       0.00      0.00      0.00         1\n",
            "         212       0.00      0.00      0.00         0\n",
            "         216       0.00      0.00      0.00         2\n",
            "         217       0.00      0.00      0.00         1\n",
            "         219       0.00      0.00      0.00         1\n",
            "         220       0.00      0.00      0.00         0\n",
            "         224       0.00      0.00      0.00         2\n",
            "         227       1.00      1.00      1.00         1\n",
            "         229       0.00      0.00      0.00         1\n",
            "         230       0.00      0.00      0.00         1\n",
            "         233       0.00      0.00      0.00         3\n",
            "         237       0.00      0.00      0.00         1\n",
            "         238       0.00      0.00      0.00         1\n",
            "         240       0.00      0.00      0.00         1\n",
            "         242       0.00      0.00      0.00         1\n",
            "         244       0.00      0.00      0.00         0\n",
            "         246       0.00      0.00      0.00         1\n",
            "         247       0.00      0.00      0.00         1\n",
            "         248       0.00      0.00      0.00         3\n",
            "         252       0.00      0.00      0.00         1\n",
            "         254       0.00      0.00      0.00         1\n",
            "         257       0.00      0.00      0.00         3\n",
            "         258       1.00      1.00      1.00         1\n",
            "         260       0.00      0.00      0.00         1\n",
            "         261       0.00      0.00      0.00         0\n",
            "         262       0.00      0.00      0.00         1\n",
            "         264       0.00      0.00      0.00         2\n",
            "         265       0.00      0.00      0.00         0\n",
            "         266       0.00      0.00      0.00         1\n",
            "         267       0.00      0.00      0.00         1\n",
            "         271       0.00      0.00      0.00         3\n",
            "         273       1.00      0.50      0.67         2\n",
            "         276       0.00      0.00      0.00         1\n",
            "         278       0.00      0.00      0.00         1\n",
            "         279       0.00      0.00      0.00         1\n",
            "         282       0.00      0.00      0.00         1\n",
            "         284       0.00      0.00      0.00         1\n",
            "         285       0.00      0.00      0.00         1\n",
            "         290       0.00      0.00      0.00         1\n",
            "         291       0.00      0.00      0.00         0\n",
            "         293       0.00      0.00      0.00         0\n",
            "         295       0.00      0.00      0.00         1\n",
            "         297       0.00      0.00      0.00         1\n",
            "         298       0.00      0.00      0.00         0\n",
            "         300       0.00      0.00      0.00         1\n",
            "         301       0.00      0.00      0.00         1\n",
            "         303       0.00      0.00      0.00         1\n",
            "         307       0.00      0.00      0.00         1\n",
            "         310       0.00      0.00      0.00         1\n",
            "         312       0.00      0.00      0.00         1\n",
            "         313       0.00      0.00      0.00         1\n",
            "         314       0.00      0.00      0.00         1\n",
            "         315       0.00      0.00      0.00         1\n",
            "         316       0.00      0.00      0.00         1\n",
            "         318       0.50      1.00      0.67         1\n",
            "         319       0.00      0.00      0.00         2\n",
            "         323       0.00      0.00      0.00         1\n",
            "         329       0.00      0.00      0.00         1\n",
            "         331       0.00      0.00      0.00         0\n",
            "         332       0.00      0.00      0.00         0\n",
            "         334       0.00      0.00      0.00         0\n",
            "         335       0.00      0.00      0.00         1\n",
            "         338       0.00      0.00      0.00         1\n",
            "         340       0.00      0.00      0.00         1\n",
            "         341       0.00      0.00      0.00         1\n",
            "         342       0.00      0.00      0.00         0\n",
            "         343       0.00      0.00      0.00         1\n",
            "         344       0.00      0.00      0.00         1\n",
            "         345       0.00      0.00      0.00         1\n",
            "         347       0.00      0.00      0.00         1\n",
            "         349       0.00      0.00      0.00         2\n",
            "         353       0.00      0.00      0.00         1\n",
            "         354       0.00      0.00      0.00         0\n",
            "         355       0.00      0.00      0.00         1\n",
            "         357       0.00      0.00      0.00         1\n",
            "         358       0.00      0.00      0.00         2\n",
            "         364       0.00      0.00      0.00         1\n",
            "         366       0.00      0.00      0.00         1\n",
            "         369       0.00      0.00      0.00         1\n",
            "         371       0.00      0.00      0.00         1\n",
            "         373       0.00      0.00      0.00         1\n",
            "         374       0.00      0.00      0.00         1\n",
            "         375       1.00      0.50      0.67         2\n",
            "         377       0.00      0.00      0.00         1\n",
            "         379       0.00      0.00      0.00         1\n",
            "         382       0.00      0.00      0.00         1\n",
            "         384       0.00      0.00      0.00         1\n",
            "         387       0.00      0.00      0.00         1\n",
            "         388       0.00      0.00      0.00         0\n",
            "         391       0.00      0.00      0.00         1\n",
            "         393       0.00      0.00      0.00         1\n",
            "         395       0.00      0.00      0.00         1\n",
            "         396       0.00      0.00      0.00         1\n",
            "         397       0.00      0.00      0.00         1\n",
            "         400       0.00      0.00      0.00         0\n",
            "         403       0.00      0.00      0.00         1\n",
            "         416       0.00      0.00      0.00         1\n",
            "         417       0.00      0.00      0.00         0\n",
            "         418       0.00      0.00      0.00         1\n",
            "         424       0.00      0.00      0.00         0\n",
            "         428       0.00      0.00      0.00         1\n",
            "         431       0.00      0.00      0.00         2\n",
            "         432       1.00      1.00      1.00         1\n",
            "         433       0.00      0.00      0.00         0\n",
            "         434       0.33      1.00      0.50         1\n",
            "         435       0.00      0.00      0.00         1\n",
            "         436       0.00      0.00      0.00         1\n",
            "         438       0.00      0.00      0.00         0\n",
            "         443       0.00      0.00      0.00         1\n",
            "         444       0.00      0.00      0.00         1\n",
            "         447       0.00      0.00      0.00         0\n",
            "         453       0.00      0.00      0.00         1\n",
            "         454       0.00      0.00      0.00         1\n",
            "         455       0.00      0.00      0.00         1\n",
            "         458       0.00      0.00      0.00         1\n",
            "         459       0.00      0.00      0.00         1\n",
            "         461       0.00      0.00      0.00         1\n",
            "         463       0.00      0.00      0.00         0\n",
            "         469       0.00      0.00      0.00         1\n",
            "         472       0.00      0.00      0.00         1\n",
            "         475       0.00      0.00      0.00         1\n",
            "         478       0.00      0.00      0.00         1\n",
            "         481       0.00      0.00      0.00         1\n",
            "         482       0.00      0.00      0.00         0\n",
            "         483       0.00      0.00      0.00         1\n",
            "         484       0.00      0.00      0.00         1\n",
            "         488       0.00      0.00      0.00         0\n",
            "         489       0.00      0.00      0.00         1\n",
            "         490       0.00      0.00      0.00         0\n",
            "         491       0.25      1.00      0.40         2\n",
            "         492       0.00      0.00      0.00         2\n",
            "         493       0.00      0.00      0.00         1\n",
            "         494       0.00      0.00      0.00         0\n",
            "         495       0.00      0.00      0.00         0\n",
            "         496       0.00      0.00      0.00         0\n",
            "         497       0.00      0.00      0.00         1\n",
            "         498       0.00      0.00      0.00         0\n",
            "         499       0.00      0.00      0.00         1\n",
            "         500       1.00      1.00      1.00         1\n",
            "         501       0.00      0.00      0.00         0\n",
            "         502       0.33      1.00      0.50         1\n",
            "         504       0.67      1.00      0.80         2\n",
            "         507       0.50      0.20      0.29         5\n",
            "         508       0.00      0.00      0.00         0\n",
            "         509       0.00      0.00      0.00         0\n",
            "         510       1.00      1.00      1.00         1\n",
            "         511       0.00      0.00      0.00         1\n",
            "         513       0.00      0.00      0.00         0\n",
            "         515       0.00      0.00      0.00         1\n",
            "         516       0.00      0.00      0.00         1\n",
            "         517       0.00      0.00      0.00         2\n",
            "         518       0.00      0.00      0.00         0\n",
            "         519       0.00      0.00      0.00         0\n",
            "         520       0.00      0.00      0.00         1\n",
            "         521       0.25      1.00      0.40         1\n",
            "         522       1.00      0.50      0.67         2\n",
            "         523       0.00      0.00      0.00         0\n",
            "         525       0.00      0.00      0.00         1\n",
            "         526       0.00      0.00      0.00         0\n",
            "         527       0.00      0.00      0.00         1\n",
            "         528       0.00      0.00      0.00         0\n",
            "         531       0.00      0.00      0.00         0\n",
            "         533       1.00      0.50      0.67         2\n",
            "         535       1.00      1.00      1.00         1\n",
            "         537       0.00      0.00      0.00         1\n",
            "         540       0.00      0.00      0.00         1\n",
            "         542       0.00      0.00      0.00         0\n",
            "         544       0.00      0.00      0.00         1\n",
            "         548       0.00      0.00      0.00         1\n",
            "         549       0.00      0.00      0.00         0\n",
            "         551       0.00      0.00      0.00         1\n",
            "         552       0.00      0.00      0.00         0\n",
            "         553       1.00      1.00      1.00         1\n",
            "         554       0.00      0.00      0.00         1\n",
            "         555       0.00      0.00      0.00         1\n",
            "         556       0.00      0.00      0.00         1\n",
            "         557       0.00      0.00      0.00         1\n",
            "         563       0.00      0.00      0.00         1\n",
            "         564       0.00      0.00      0.00         2\n",
            "         565       0.00      0.00      0.00         1\n",
            "         566       0.00      0.00      0.00         1\n",
            "         568       0.00      0.00      0.00         1\n",
            "         572       0.20      1.00      0.33         2\n",
            "         579       0.00      0.00      0.00         1\n",
            "         580       0.00      0.00      0.00         2\n",
            "         581       0.00      0.00      0.00         1\n",
            "         585       0.00      0.00      0.00         0\n",
            "         586       0.00      0.00      0.00         0\n",
            "         587       0.00      0.00      0.00         2\n",
            "         588       0.00      0.00      0.00         2\n",
            "         589       1.00      1.00      1.00         1\n",
            "         590       0.00      0.00      0.00         1\n",
            "         591       0.00      0.00      0.00         1\n",
            "         594       1.00      1.00      1.00         1\n",
            "         599       0.00      0.00      0.00         0\n",
            "         602       0.00      0.00      0.00         1\n",
            "         604       0.00      0.00      0.00         1\n",
            "         605       0.00      0.00      0.00         0\n",
            "         606       0.00      0.00      0.00         1\n",
            "         609       0.00      0.00      0.00         1\n",
            "         610       0.00      0.00      0.00         1\n",
            "         612       0.00      0.00      0.00         1\n",
            "         615       0.00      0.00      0.00         1\n",
            "         616       0.00      0.00      0.00         1\n",
            "         618       0.00      0.00      0.00         1\n",
            "         620       0.00      0.00      0.00         0\n",
            "         621       0.00      0.00      0.00         1\n",
            "         622       0.00      0.00      0.00         1\n",
            "         624       0.00      0.00      0.00         1\n",
            "         626       0.00      0.00      0.00         0\n",
            "         629       0.00      0.00      0.00         1\n",
            "         637       0.00      0.00      0.00         1\n",
            "         641       0.00      0.00      0.00         1\n",
            "         645       0.00      0.00      0.00         0\n",
            "         646       0.00      0.00      0.00         1\n",
            "         647       0.00      0.00      0.00         1\n",
            "         648       0.00      0.00      0.00         1\n",
            "         649       0.00      0.00      0.00         1\n",
            "         652       0.00      0.00      0.00         2\n",
            "         654       0.00      0.00      0.00         0\n",
            "         656       0.00      0.00      0.00         1\n",
            "         657       0.00      0.00      0.00         1\n",
            "         660       0.00      0.00      0.00         1\n",
            "         666       0.00      0.00      0.00         0\n",
            "         668       1.00      0.50      0.67         2\n",
            "         669       0.00      0.00      0.00         0\n",
            "         672       0.00      0.00      0.00         1\n",
            "         673       0.00      0.00      0.00         1\n",
            "         676       0.00      0.00      0.00         1\n",
            "         677       0.00      0.00      0.00         1\n",
            "         678       0.00      0.00      0.00         1\n",
            "         679       0.00      0.00      0.00         1\n",
            "         681       0.00      0.00      0.00         1\n",
            "         685       0.00      0.00      0.00         0\n",
            "         686       1.00      1.00      1.00         1\n",
            "         687       0.00      0.00      0.00         0\n",
            "         689       0.00      0.00      0.00         1\n",
            "         692       0.00      0.00      0.00         2\n",
            "         693       0.00      0.00      0.00         0\n",
            "         694       0.25      1.00      0.40         1\n",
            "         695       0.00      0.00      0.00         1\n",
            "         697       0.00      0.00      0.00         1\n",
            "         698       0.00      0.00      0.00         0\n",
            "         699       0.00      0.00      0.00         1\n",
            "         701       0.00      0.00      0.00         1\n",
            "         702       0.00      0.00      0.00         0\n",
            "         703       0.00      0.00      0.00         1\n",
            "         704       0.00      0.00      0.00         0\n",
            "         712       0.00      0.00      0.00         1\n",
            "         713       0.00      0.00      0.00         2\n",
            "         714       0.00      0.00      0.00         1\n",
            "         716       0.00      0.00      0.00         0\n",
            "         730       0.00      0.00      0.00         0\n",
            "         732       0.00      0.00      0.00         0\n",
            "         734       0.00      0.00      0.00         1\n",
            "         735       0.00      0.00      0.00         0\n",
            "         736       0.00      0.00      0.00         0\n",
            "         739       0.00      0.00      0.00         0\n",
            "         740       0.00      0.00      0.00         2\n",
            "         743       0.00      0.00      0.00         1\n",
            "         744       0.00      0.00      0.00         1\n",
            "         746       0.00      0.00      0.00         1\n",
            "         748       0.00      0.00      0.00         0\n",
            "         749       0.00      0.00      0.00         0\n",
            "         750       0.00      0.00      0.00         2\n",
            "         754       0.00      0.00      0.00         1\n",
            "         756       0.00      0.00      0.00         1\n",
            "         758       0.00      0.00      0.00         1\n",
            "         761       0.00      0.00      0.00         0\n",
            "         767       0.00      0.00      0.00         0\n",
            "         772       0.00      0.00      0.00         1\n",
            "         774       0.00      0.00      0.00         1\n",
            "         775       0.00      0.00      0.00         1\n",
            "         776       0.00      0.00      0.00         1\n",
            "         780       0.00      0.00      0.00         1\n",
            "         781       0.00      0.00      0.00         0\n",
            "         782       0.00      0.00      0.00         1\n",
            "         784       1.00      1.00      1.00         1\n",
            "         785       0.00      0.00      0.00         1\n",
            "         787       0.00      0.00      0.00         1\n",
            "         789       0.00      0.00      0.00         1\n",
            "         790       0.00      0.00      0.00         0\n",
            "         793       0.00      0.00      0.00         1\n",
            "         798       0.00      0.00      0.00         0\n",
            "         800       0.00      0.00      0.00         0\n",
            "         801       0.00      0.00      0.00         1\n",
            "         802       0.00      0.00      0.00         1\n",
            "         803       0.00      0.00      0.00         0\n",
            "         805       0.00      0.00      0.00         0\n",
            "         806       0.00      0.00      0.00         1\n",
            "         811       0.00      0.00      0.00         1\n",
            "         812       0.00      0.00      0.00         1\n",
            "         813       0.00      0.00      0.00         1\n",
            "         816       0.00      0.00      0.00         0\n",
            "         818       0.00      0.00      0.00         1\n",
            "         819       0.00      0.00      0.00         1\n",
            "         821       1.00      1.00      1.00         1\n",
            "         822       1.00      1.00      1.00         1\n",
            "         825       1.00      1.00      1.00         1\n",
            "         826       1.00      1.00      1.00         1\n",
            "         830       0.00      0.00      0.00         1\n",
            "         836       0.00      0.00      0.00         1\n",
            "         837       0.00      0.00      0.00         1\n",
            "         838       1.00      1.00      1.00         1\n",
            "         842       0.00      0.00      0.00         1\n",
            "         845       0.00      0.00      0.00         1\n",
            "         846       0.00      0.00      0.00         0\n",
            "         847       0.00      0.00      0.00         1\n",
            "         851       0.00      0.00      0.00         1\n",
            "         853       0.00      0.00      0.00         1\n",
            "         854       0.00      0.00      0.00         1\n",
            "         855       0.00      0.00      0.00         1\n",
            "         856       0.00      0.00      0.00         1\n",
            "         859       0.00      0.00      0.00         0\n",
            "         861       0.00      0.00      0.00         1\n",
            "         865       0.00      0.00      0.00         1\n",
            "         866       0.00      0.00      0.00         0\n",
            "         868       1.00      1.00      1.00         1\n",
            "         871       0.00      0.00      0.00         1\n",
            "         872       0.00      0.00      0.00         0\n",
            "         873       0.00      0.00      0.00         1\n",
            "         877       0.00      0.00      0.00         1\n",
            "         882       0.00      0.00      0.00         1\n",
            "         889       0.00      0.00      0.00         1\n",
            "         890       0.00      0.00      0.00         1\n",
            "         892       0.00      0.00      0.00         1\n",
            "         893       0.00      0.00      0.00         1\n",
            "         894       0.00      0.00      0.00         1\n",
            "         895       0.00      0.00      0.00         1\n",
            "         896       0.00      0.00      0.00         0\n",
            "         902       0.00      0.00      0.00         1\n",
            "         903       0.00      0.00      0.00         1\n",
            "         906       0.00      0.00      0.00         0\n",
            "         913       0.00      0.00      0.00         1\n",
            "         917       0.00      0.00      0.00         2\n",
            "         918       0.00      0.00      0.00         0\n",
            "         921       0.00      0.00      0.00         1\n",
            "         924       0.00      0.00      0.00         1\n",
            "         926       0.00      0.00      0.00         1\n",
            "         931       0.00      0.00      0.00         1\n",
            "         932       0.00      0.00      0.00         1\n",
            "         933       0.00      0.00      0.00         1\n",
            "         935       0.00      0.00      0.00         1\n",
            "         943       0.00      0.00      0.00         1\n",
            "         944       0.00      0.00      0.00         1\n",
            "         946       0.00      0.00      0.00         1\n",
            "         947       0.00      0.00      0.00         3\n",
            "         948       0.00      0.00      0.00         1\n",
            "         949       0.00      0.00      0.00         1\n",
            "         950       0.00      0.00      0.00         1\n",
            "         951       0.00      0.00      0.00         0\n",
            "         952       0.00      0.00      0.00         1\n",
            "         954       0.00      0.00      0.00         1\n",
            "         957       0.00      0.00      0.00         0\n",
            "         958       0.00      0.00      0.00         1\n",
            "         959       0.00      0.00      0.00         1\n",
            "         960       0.00      0.00      0.00         0\n",
            "         965       0.00      0.00      0.00         2\n",
            "         966       0.00      0.00      0.00         1\n",
            "         967       0.00      0.00      0.00         1\n",
            "         969       0.00      0.00      0.00         1\n",
            "         973       0.00      0.00      0.00         1\n",
            "         975       0.00      0.00      0.00         1\n",
            "         976       0.00      0.00      0.00         0\n",
            "         977       0.00      0.00      0.00         0\n",
            "         979       0.00      0.00      0.00         1\n",
            "         983       0.00      0.00      0.00         1\n",
            "         984       0.00      0.00      0.00         0\n",
            "         985       0.00      0.00      0.00         1\n",
            "         988       0.00      0.00      0.00         1\n",
            "         993       0.00      0.00      0.00         0\n",
            "         995       0.00      0.00      0.00         0\n",
            "         998       0.00      0.00      0.00         2\n",
            "         999       0.00      0.00      0.00         1\n",
            "        1004       0.00      0.00      0.00         1\n",
            "        1013       0.00      0.00      0.00         0\n",
            "        1016       0.00      0.00      0.00         1\n",
            "        1018       0.00      0.00      0.00         2\n",
            "        1022       0.00      0.00      0.00         1\n",
            "        1023       0.00      0.00      0.00         1\n",
            "        1024       0.00      0.00      0.00         0\n",
            "        1025       0.00      0.00      0.00         0\n",
            "        1027       0.00      0.00      0.00         1\n",
            "        1029       0.00      0.00      0.00         1\n",
            "        1030       0.00      0.00      0.00         1\n",
            "        1032       0.00      0.00      0.00         1\n",
            "        1034       0.00      0.00      0.00         1\n",
            "        1035       0.00      0.00      0.00         1\n",
            "        1036       0.00      0.00      0.00         1\n",
            "        1039       0.00      0.00      0.00         2\n",
            "        1040       0.00      0.00      0.00         1\n",
            "        1041       0.00      0.00      0.00         0\n",
            "        1042       0.00      0.00      0.00         2\n",
            "        1043       0.00      0.00      0.00         0\n",
            "        1044       0.00      0.00      0.00         0\n",
            "        1046       0.00      0.00      0.00         1\n",
            "        1047       0.00      0.00      0.00         1\n",
            "        1049       0.00      0.00      0.00         1\n",
            "        1050       0.00      0.00      0.00         1\n",
            "        1051       0.00      0.00      0.00         1\n",
            "        1052       0.00      0.00      0.00         1\n",
            "        1056       0.00      0.00      0.00         1\n",
            "        1057       0.00      0.00      0.00         1\n",
            "        1058       0.00      0.00      0.00         0\n",
            "        1063       0.00      0.00      0.00         0\n",
            "        1066       0.00      0.00      0.00         0\n",
            "        1070       0.00      0.00      0.00         0\n",
            "        1072       0.00      0.00      0.00         1\n",
            "        1073       0.00      0.00      0.00         1\n",
            "        1076       0.00      0.00      0.00         0\n",
            "        1078       0.00      0.00      0.00         1\n",
            "        1079       0.00      0.00      0.00         1\n",
            "        1081       0.00      0.00      0.00         0\n",
            "        1082       0.00      0.00      0.00         1\n",
            "        1083       0.00      0.00      0.00         1\n",
            "        1084       0.00      0.00      0.00         1\n",
            "        1085       0.00      0.00      0.00         1\n",
            "        1088       0.00      0.00      0.00         1\n",
            "        1089       0.00      0.00      0.00         1\n",
            "        1091       0.00      0.00      0.00         1\n",
            "        1092       0.00      0.00      0.00         1\n",
            "        1093       0.00      0.00      0.00         1\n",
            "        1094       0.00      0.00      0.00         1\n",
            "        1095       0.00      0.00      0.00         1\n",
            "        1096       0.00      0.00      0.00         1\n",
            "        1104       0.00      0.00      0.00         0\n",
            "        1106       0.00      0.00      0.00         0\n",
            "        1108       0.00      0.00      0.00         1\n",
            "        1113       0.00      0.00      0.00         1\n",
            "        1114       0.00      0.00      0.00         1\n",
            "        1116       0.00      0.00      0.00         1\n",
            "        1118       0.00      0.00      0.00         1\n",
            "        1120       0.00      0.00      0.00         1\n",
            "        1124       0.00      0.00      0.00         1\n",
            "        1125       0.00      0.00      0.00         1\n",
            "        1128       0.00      0.00      0.00         0\n",
            "        1130       0.00      0.00      0.00         1\n",
            "        1132       0.00      0.00      0.00         1\n",
            "        1133       0.00      0.00      0.00         0\n",
            "        1134       0.00      0.00      0.00         1\n",
            "        1135       0.00      0.00      0.00         0\n",
            "        1136       0.00      0.00      0.00         1\n",
            "        1137       0.00      0.00      0.00         1\n",
            "        1138       0.00      0.00      0.00         1\n",
            "        1141       0.00      0.00      0.00         0\n",
            "        1145       0.00      0.00      0.00         0\n",
            "        1146       0.00      0.00      0.00         1\n",
            "        1150       0.00      0.00      0.00         1\n",
            "        1152       0.00      0.00      0.00         0\n",
            "        1155       0.00      0.00      0.00         1\n",
            "        1156       0.00      0.00      0.00         1\n",
            "        1157       0.00      0.00      0.00         0\n",
            "        1158       0.00      0.00      0.00         1\n",
            "        1166       0.00      0.00      0.00         0\n",
            "        1167       0.00      0.00      0.00         1\n",
            "        1169       0.00      0.00      0.00         1\n",
            "        1170       0.00      0.00      0.00         0\n",
            "        1172       0.00      0.00      0.00         1\n",
            "        1177       0.00      0.00      0.00         0\n",
            "        1179       0.00      0.00      0.00         1\n",
            "        1180       0.00      0.00      0.00         1\n",
            "        1181       0.00      0.00      0.00         1\n",
            "        1185       0.00      0.00      0.00         1\n",
            "        1186       0.00      0.00      0.00         1\n",
            "        1187       0.00      0.00      0.00         1\n",
            "        1188       0.00      0.00      0.00         1\n",
            "        1189       0.00      0.00      0.00         0\n",
            "        1190       0.50      1.00      0.67         1\n",
            "        1192       0.00      0.00      0.00         0\n",
            "        1193       0.00      0.00      0.00         1\n",
            "        1194       0.00      0.00      0.00         0\n",
            "        1196       0.00      0.00      0.00         1\n",
            "        1197       0.00      0.00      0.00         0\n",
            "        1198       0.00      0.00      0.00         1\n",
            "        1199       0.00      0.00      0.00         0\n",
            "        1200       0.00      0.00      0.00         0\n",
            "        1202       0.00      0.00      0.00         2\n",
            "        1205       0.00      0.00      0.00         1\n",
            "        1206       1.00      1.00      1.00         1\n",
            "        1207       0.00      0.00      0.00         1\n",
            "        1211       0.00      0.00      0.00         0\n",
            "        1214       0.00      0.00      0.00         1\n",
            "        1216       0.00      0.00      0.00         2\n",
            "        1220       0.00      0.00      0.00         1\n",
            "        1222       0.00      0.00      0.00         0\n",
            "        1223       0.00      0.00      0.00         1\n",
            "        1224       0.00      0.00      0.00         1\n",
            "        1225       0.00      0.00      0.00         1\n",
            "        1226       0.00      0.00      0.00         1\n",
            "        1228       0.00      0.00      0.00         0\n",
            "        1230       0.00      0.00      0.00         0\n",
            "        1231       1.00      1.00      1.00         1\n",
            "        1232       0.00      0.00      0.00         1\n",
            "        1234       0.00      0.00      0.00         1\n",
            "        1235       0.00      0.00      0.00         1\n",
            "        1237       0.00      0.00      0.00         1\n",
            "        1243       0.00      0.00      0.00         2\n",
            "        1244       0.00      0.00      0.00         1\n",
            "        1246       0.00      0.00      0.00         0\n",
            "        1248       0.00      0.00      0.00         2\n",
            "        1253       0.00      0.00      0.00         0\n",
            "        1254       0.00      0.00      0.00         1\n",
            "        1257       0.00      0.00      0.00         0\n",
            "        1258       0.00      0.00      0.00         1\n",
            "        1261       0.00      0.00      0.00         1\n",
            "        1263       0.00      0.00      0.00         1\n",
            "        1264       0.00      0.00      0.00         1\n",
            "        1266       0.00      0.00      0.00         0\n",
            "        1267       0.00      0.00      0.00         1\n",
            "        1268       0.00      0.00      0.00         1\n",
            "        1269       0.00      0.00      0.00         0\n",
            "        1270       0.00      0.00      0.00         1\n",
            "        1271       0.00      0.00      0.00         1\n",
            "        1272       0.00      0.00      0.00         1\n",
            "        1274       0.00      0.00      0.00         1\n",
            "        1280       0.00      0.00      0.00         1\n",
            "        1286       0.00      0.00      0.00         1\n",
            "        1289       0.00      0.00      0.00         1\n",
            "        1290       0.00      0.00      0.00         1\n",
            "        1293       0.00      0.00      0.00         1\n",
            "        1295       0.00      0.00      0.00         1\n",
            "        1297       0.00      0.00      0.00         1\n",
            "        1299       0.00      0.00      0.00         1\n",
            "        1301       0.00      0.00      0.00         1\n",
            "        1303       0.00      0.00      0.00         0\n",
            "        1304       0.00      0.00      0.00         1\n",
            "        1305       0.00      0.00      0.00         2\n",
            "        1306       0.00      0.00      0.00         1\n",
            "        1307       0.00      0.00      0.00         0\n",
            "        1309       0.00      0.00      0.00         1\n",
            "        1310       0.00      0.00      0.00         1\n",
            "        1311       0.00      0.00      0.00         2\n",
            "        1312       0.00      0.00      0.00         1\n",
            "        1313       0.00      0.00      0.00         0\n",
            "        1322       0.00      0.00      0.00         1\n",
            "        1323       0.00      0.00      0.00         1\n",
            "        1325       1.00      1.00      1.00         1\n",
            "        1327       0.00      0.00      0.00         2\n",
            "        1334       0.50      1.00      0.67         1\n",
            "        1337       0.00      0.00      0.00         1\n",
            "        1338       0.00      0.00      0.00         1\n",
            "        1339       0.00      0.00      0.00         1\n",
            "        1340       0.00      0.00      0.00         1\n",
            "        1341       0.00      0.00      0.00         1\n",
            "        1346       0.00      0.00      0.00         1\n",
            "        1347       0.00      0.00      0.00         1\n",
            "        1351       0.00      0.00      0.00         0\n",
            "        1355       0.00      0.00      0.00         1\n",
            "        1356       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.10       600\n",
            "   macro avg       0.06      0.07      0.06       600\n",
            "weighted avg       0.09      0.10      0.08       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "##gives the f1 score, recall, precision\n",
        "print(classification_report(y_val, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "R9xtJfDRTfvU"
      },
      "outputs": [],
      "source": [
        "# # save the model trained\n",
        "# with open('/content/lr.pkl','wb') as f:\n",
        "#     pickle.dump(lr,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "efPYmS-mFGY9"
      },
      "outputs": [],
      "source": [
        "# #using logistic regression model\n",
        "# import os\n",
        "# import pickle\n",
        "\n",
        "# ##checks if the model already exist\n",
        "# if os.path.exists(\"lr.pkl\"):\n",
        "#   with open('lr.pkl', 'rb') as f: ##If it exist it uses it\n",
        "#       lr = pickle.load(f)\n",
        "# else: ##if the model doesn't exist\n",
        "#   lr = LogisticRegression(max_iter=1000)\n",
        "#   lr.fit(X_train_vectorized, y_train)\n",
        "\n",
        "#   # save the model trained\n",
        "#   with open('/content/lr.pkl','wb') as f:\n",
        "#       pickle.dump(lr,f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc-zw67v-TOS"
      },
      "source": [
        "Testing on user asking question for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "oBrm_M6rNATb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518932a0-9e28-4839-f7de-212ea9c9cfe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi\n",
            "Write quit or bye when you have finished asking your questions\n",
            "Question: hi\n",
            "Response: Michael Jackson\n",
            "Question: who is beyonce\n",
            "Response: Michael Jackson\n",
            "Question: when was beyonce born\n",
            "Response: Michael Jackson\n",
            "Question: which group was beyonce in\n",
            "Response: Lady Gaga\n",
            "Question: where did nomads live\n",
            "Response: Chaillot\n",
            "Question: when did beyonce start becoming popular\t\n",
            "Response: in the late 1990s\n",
            "Question: in what city and state did beyonce grow up\n",
            "Response: Houston, Texas\n",
            "Question: bye\n",
            "End of QA session\n"
          ]
        }
      ],
      "source": [
        "# getting user input and preforming the question and answer\n",
        "closeChatWords = ['bye', 'quit']\n",
        "\n",
        "print(\"Hi\")\n",
        "print(\"Write quit or bye when you have finished asking your questions\")\n",
        "while True:\n",
        "  user_input = input(\"Question: \")\n",
        "  if user_input.lower() in closeChatWords:\n",
        "    print(\"End of QA session\")\n",
        "    break\n",
        "  else:\n",
        "    user_input_vectorized = vectorizer.transform([user_input])\n",
        "    predicted_label = lr.predict(user_input_vectorized)[0] ###getting the prediction\n",
        "    predAns = [answer for answer, label in ansToLabel.items() if label == predicted_label][0] ##finding the prediction in the ansLabel\n",
        "    ##doing a response if the predicted is None\n",
        "    if predAns == None:\n",
        "      print(\"Response: I don't know how to answer this question, ask me another question\")\n",
        "    else:\n",
        "      ##give the answser\n",
        "      print(\"Response:\", predAns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen from the chat above the bottom half shows the questions i got from the training data, which were all answered correctly, while there was wrong predictions in the one above. **NB - more training is needed**"
      ],
      "metadata": {
        "id": "PVEIeuOJA-hv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU1Ma270axwI"
      },
      "source": [
        "## Potential extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL3WdSBFalGh"
      },
      "source": [
        "**Improved the performance of a model on the task by finding additional training data from a similar/related dataset by training a similar dataset called CoQA and QuAC [1].**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k31kBloGLwxB"
      },
      "source": [
        "CoQA:\n",
        "https://downloads.cs.stanford.edu/nlp/data/coqa/coqa-dev-v1.0.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joas2iKBL2cr"
      },
      "source": [
        "QuAC: https://stanfordnlp.github.io/coqa/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxgy7TdOST1v"
      },
      "source": [
        "**Turning the QA system into a chatbot - so will try to implement a dialog manager and will preform evaluation on this system.[3]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlhPD3a9H5-z"
      },
      "source": [
        "## References\n",
        "\n",
        "\n",
        "1.   https://arxiv.org/pdf/1809.10735.pdf\n",
        "2.   https://www.sciencedirect.com/science/article/pii/S2772442523000655?ref=pdf_download&fr=RR-2&rr=84248bf61c1c9a24\n",
        "3. https://en.wikipedia.org/wiki/Dialog_manager\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}